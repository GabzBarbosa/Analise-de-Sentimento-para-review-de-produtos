{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabzBarbosa/Analise-de-Sentimento-para-review-de-produtos/blob/main/Analise_de_Sentimento_Review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip -q install google-genai"
      ],
      "metadata": {
        "id": "CP0TKDCMu7-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "OjwJghQJu8ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o cliente da SDK do Gemini\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "KBZ9nIckvSGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np # Importado para lidar com NaN\n",
        "from IPython.display import HTML, Markdown\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- Configuração da API do Gemini ---\n",
        "# É altamente recomendável carregar sua chave de forma segura, por exemplo, de variáveis de ambiente.\n",
        "# genai.configure(api_key=\"SUA_CHAVE_API_DO_GEMINI\")\n",
        "# ou, se você tiver configurado a variável de ambiente GOOGLE_API_KEY\n",
        "genai.configure()\n",
        "\n",
        "# --- Carregar o modelo Gemini ---\n",
        "# O modelo 'gemini-1.5-pro' é geralmente mais robusto para gerar JSON estruturado.\n",
        "# Se você tiver acesso ao 'gemini-2.0-flash' e ele funcionar para saída JSON, pode usá-lo.\n",
        "MODEL_ID = \"gemini-2.0-flash\"\n",
        "model = genai.GenerativeModel(MODEL_ID)\n",
        "\n",
        "# --- Instalação de biblioteca (executar apenas uma vez) ---\n",
        "# Garante que openpyxl esteja instalado para exportar para .xlsx\n",
        "try:\n",
        "    import openpyxl\n",
        "except ImportError:\n",
        "    print(\"Instalando openpyxl...\")\n",
        "    !pip install -q openpyxl\n",
        "    import openpyxl\n",
        "    print(\"openpyxl instalado com sucesso.\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Função para carregar a planilha ---\n",
        "def carregar_planilha(caminho_arquivo):\n",
        "    \"\"\"\n",
        "    Carrega uma planilha (CSV ou Excel) e retorna um DataFrame do pandas.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if caminho_arquivo.endswith('.csv'):\n",
        "            df = pd.read_csv(caminho_arquivo)\n",
        "        elif caminho_arquivo.endswith(('.xls', '.xlsx')):\n",
        "            df = pd.read_excel(caminho_arquivo)\n",
        "        else:\n",
        "            raise ValueError(\"Formato de arquivo não suportado. Use .csv, .xls ou .xlsx\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: Arquivo '{caminho_arquivo}' não encontrado.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao carregar a planilha: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Função para salvar o relatório em XLSX ---\n",
        "def salvar_relatorio_xlsx(nome_arquivo, df_relatorio):\n",
        "    \"\"\"\n",
        "    Salva o DataFrame fornecido em um arquivo Excel (.xlsx).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df_relatorio.to_excel(nome_arquivo, index=False, engine='openpyxl')\n",
        "        print(f\"Relatório salvo com sucesso em '{nome_arquivo}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao salvar o relatório em XLSX: {e}\")\n",
        "\n",
        "# --- Caminho para sua planilha de entrada ---\n",
        "caminho_da_planilha = '/content/Teste Analise de Sentimento - Página1.csv'\n",
        "# --- Nome do arquivo para salvar o relatório de saída (XLSX) ---\n",
        "nome_do_relatorio_xlsx = 'relatorio_analise_qualidade_clientes.xlsx'\n",
        "\n",
        "# Carrega os dados da planilha\n",
        "df_avaliacoes = carregar_planilha(caminho_da_planilha)\n",
        "\n",
        "if df_avaliacoes is not None:\n",
        "    # Garante que as colunas 'id', 'nota', 'comentario' e 'Recomenda produto' existam\n",
        "    colunas_necessarias = ['id', 'nota', 'comentario', 'Recomenda produto']\n",
        "    if not all(coluna in df_avaliacoes.columns for coluna in colunas_necessarias):\n",
        "        print(f\"Erro: Uma ou mais colunas necessárias ({', '.join(colunas_necessarias)}) não foram encontradas na planilha.\")\n",
        "    else:\n",
        "        # CONVERSÃO DA COLUNA 'Recomenda produto' PARA NUMÉRICO (1 para 'Sim', 0 para 'Não')\n",
        "        # Lida com valores nulos (NaN) preenchendo-os com 0 antes da conversão para int\n",
        "        df_avaliacoes['Recomenda produto'] = df_avaliacoes['Recomenda produto'].astype(str).str.lower().map({'sim': 1, 'não': 0}).fillna(0).astype(int)\n",
        "\n",
        "        # Pré-processamento dos dados para consolidar por ID\n",
        "        dados_consolidados_para_gemini = []\n",
        "        for id_cliente, grupo in df_avaliacoes.groupby('id'):\n",
        "            media_nota = grupo['nota'].mean()\n",
        "            # Garante que o percentual seja calculado apenas se houver avaliações no grupo\n",
        "            percentual_recomendacao = (grupo['Recomenda produto'].sum() / len(grupo) * 100) if len(grupo) > 0 else 0\n",
        "\n",
        "            # Converte os comentários para uma lista, substituindo NaN por None\n",
        "            comentarios_cliente = grupo['comentario'].replace({np.nan: None}).tolist()\n",
        "\n",
        "            dados_consolidados_para_gemini.append({\n",
        "                \"id_cliente\": str(id_cliente), # Garante que o ID seja uma string no JSON\n",
        "                \"media_nota\": round(media_nota, 2),\n",
        "                \"percentual_recomendacao\": round(percentual_recomendacao, 2),\n",
        "                \"comentarios\": comentarios_cliente\n",
        "            })\n",
        "\n",
        "        # Converte a lista de dicionários para uma string JSON formatada\n",
        "        json_input_para_gemini = json.dumps(dados_consolidados_para_gemini, indent=2, ensure_ascii=False)\n",
        "\n",
        "        if json_input_para_gemini.strip():\n",
        "            # --- Chamar a API do Gemini para a curadoria e resumo em JSON ---\n",
        "            prompt_curadoria = f\"\"\"\n",
        "            Você é um analista de qualidade. Abaixo estão avaliações de clientes em formato JSON, consolidadas por ID, incluindo média de nota, percentual de recomendação e os comentários brutos.\n",
        "\n",
        "            Sua tarefa é:\n",
        "            1. Para cada cliente (ID), gerar um resumo conciso do feedback e identificar as principais sugestões de melhoria específicas para o produto/serviço relacionado a esse cliente.\n",
        "            2. O resultado DEVE ser um objeto JSON. Este objeto JSON deve conter uma lista de objetos, onde cada objeto representa um cliente analisado.\n",
        "            3. Cada objeto de cliente no JSON DEVE ter as seguintes chaves (sempre presentes):\n",
        "               - \"id_cliente\": (string) O ID do cliente.\n",
        "               - \"Quantidade_Reviews\": (Numeric) Conta o total de avaliações relacionadas a id_cliente.\n",
        "               - \"media_nota\": (Numeric) Média total das notas relacionadas a id_cliente.\n",
        "               - \"resumo_feedback\": (string) Um resumo conciso do feedback do cliente.\n",
        "               - \"sugestoes_melhoria\": (array de strings) Uma lista de sugestões de melhoria específicas para o produto/serviço relacionadas ao feedback deste cliente. Se não houver sugestões, use um array vazio `[]`.\n",
        "               - \"sentimento_geral\": (string) O sentimento geral da avaliação (ex: \"Positivo\", \"Neutro\", \"Negativo\").\n",
        "\n",
        "            Exemplo de formato de saída JSON:\n",
        "            ```json\n",
        "            [\n",
        "              {{\n",
        "                \"id_cliente\": \"ClienteA\",\n",
        "                \"Quantidade_Reviews\": \"23 Avaliações Recebidas\"\n",
        "                \"media_nota\": \"1.5\",\n",
        "                \"resumo_feedback\": \"Cliente satisfeito com a entrega rápida, mas achou o preço alto.\",\n",
        "                \"sugestoes_melhoria\": [\"Revisar precificação\", \"Destacar custo-benefício\"],\n",
        "                \"sentimento_geral\": \"Neutro\"\n",
        "              }},\n",
        "              {{\n",
        "                \"id_cliente\": \"ClienteB\",\n",
        "                \"Quantidade_Reviews\": \"2 Avaliações Recebidas\"\n",
        "                \"media_nota\": \"4.5\",\n",
        "                \"resumo_feedback\": \"Produto de excelente qualidade e ótimo atendimento. Recomenda fortemente.\",\n",
        "                \"sugestoes_melhoria\": [],\n",
        "                \"sentimento_geral\": \"Positivo\"\n",
        "              }}\n",
        "            ]\n",
        "            ```\n",
        "\n",
        "            Dados dos Clientes (JSON):\n",
        "            {json_input_para_gemini}\n",
        "            \"\"\"\n",
        "\n",
        "            print(\"Gerando relatório de curadoria de comentários com Gemini (esperando JSON)...\")\n",
        "            try:\n",
        "                resposta_gemini = model.generate_content(\n",
        "                    prompt_curadoria,\n",
        "                    generation_config=genai.types.GenerationConfig(\n",
        "                        temperature=0.2,\n",
        "                        max_output_tokens=4000,\n",
        "                        response_mime_type=\"application/json\"\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                json_string_resposta = resposta_gemini.text\n",
        "\n",
        "                print(\"\\n--- Resposta JSON do Gemini (para depuração) ---\\n\")\n",
        "                print(json_string_resposta)\n",
        "                print(\"\\n-------------------------------------------------\\n\")\n",
        "\n",
        "                dados_relatorio = json.loads(json_string_resposta)\n",
        "\n",
        "                df_relatorio_final = pd.DataFrame(dados_relatorio)\n",
        "\n",
        "                display(Markdown(f\"## Relatório de Análise de Qualidade (Dados Tabulares):\\n\"))\n",
        "                display(df_relatorio_final)\n",
        "\n",
        "                # --- Salvar o relatório gerado em XLSX ---\n",
        "                salvar_relatorio_xlsx(nome_do_relatorio_xlsx, df_relatorio_final)\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Erro: A resposta do Gemini não é um JSON válido. Verifique o prompt e a resposta. Erro: {e}\")\n",
        "                print(f\"Resposta bruta recebida: {resposta_gemini.text}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Ocorreu um erro ao chamar a API do Gemini ou processar o relatório: {e}\")\n",
        "        else:\n",
        "            print(\"Não há dados válidos para processar e gerar o relatório.\")\n",
        "else:\n",
        "    print(\"Não foi possível carregar a planilha. Verifique o caminho e o formato do arquivo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JihZyrZTvSzy",
        "outputId": "a2869577-1303-4c7b-bb87-dc4220b0ff85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerando relatório de curadoria de comentários com Gemini (esperando JSON)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1705.43ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 640.16ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 662.41ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 635.35ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 684.36ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 700.44ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 568.17ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 721.71ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 634.64ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 662.83ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 584.60ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 586.51ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 811.46ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 760.80ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 534.01ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 636.78ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 864.70ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 559.16ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1521.09ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 660.01ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.42ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 711.26ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 585.14ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 536.26ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 558.61ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 786.92ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 634.76ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 735.35ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 3166.89ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 558.97ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 558.54ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 534.15ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.73ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.15ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.97ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 559.09ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 559.78ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.64ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.66ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.83ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.82ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.53ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.23ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.08ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.69ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.12ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 558.28ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 535.00ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.63ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.44ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.13ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 559.37ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 559.10ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 583.52ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.84ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.15ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 558.37ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.51ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 584.14ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 558.63ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.07ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.28ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.13ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 534.36ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 536.24ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 536.71ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.82ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.32ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 535.69ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 558.32ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.57ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 534.20ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 561.10ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.84ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.55ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.50ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.34ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.49ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 534.39ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.27ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.43ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.03ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.54ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.22ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 557.95ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.06ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.79ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.94ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.99ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.81ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.59ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.56ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.43ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.25ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 547.67ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.16ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 507.76ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.76ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.61ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.40ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 534.44ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 560.12ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.31ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ocorreu um erro ao chamar a API do Gemini ou processar o relatório: Timeout of 600.0s exceeded, last exception: 503 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: The model is overloaded. Please try again later.\n"
          ]
        }
      ]
    }
  ]
}